{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Distribution / Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Normal/Gaussian distribution, sometimes called the bell curve.\n",
    "\n",
    "The graph of the normal distribution depends on two factors - the mean and the standard deviation. \n",
    "The mean of the distribution determines the location of the center of the graph, and the standard deviation determines the height and width of the graph.\n",
    "\n",
    "When the standard deviation is small, the curve is tall and narrow; and when the standard deviation is big, the curve is short and wide.\n",
    "\n",
    "For example heights, if we consider school students few of them too small in height, most of them average in height and few of them are very large in height in that case will get the bell curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial Distribution is simply the probability of getting SUCCESS or FAILURE in experiments or surveys that is repeated multiple times.\n",
    "The binomial is a type of distribution that has two possible outcomes. \n",
    "\n",
    "For example, a coin toss has only two possible outcomes: heads or tails and taking a test could have two possible outcomes: PASS or Fail.\n",
    "\n",
    "Formulae:\n",
    "b(x; n, P) = nCx * Px * (1 – P)n – x\n",
    "\n",
    "Where:\n",
    "b = binomial probability\n",
    "x = total number of “successes” (pass or fail, heads or tails etc.)\n",
    "P = probability of a success on an individual trial\n",
    "n = number of trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between Binomial and Normal Distribution in Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##     Binomial Distribution\n",
    "     1. Binomial Distribution is to find the probability on Discrete data.\n",
    "     2.There are a finite amount of events in a binomial distribution.\n",
    "     3.If the sample size for binomial distribution is large enough, its shape will be quite similar to that of normal distribution(bell curve).\n",
    "     \n",
    "     \n",
    "##     Normal Distribution\n",
    "     1.Normal Distribution is to find the probability on continous data.\n",
    "     2.There are infinite number in a normal distribution.\n",
    "     3.Shape of the Normal Distribution is Bell-Curve\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Machine learning provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It's divide into 2 categories.\n",
    "1.Supervised Learning   2.Unsupervised Learning.\n",
    "\n",
    "Furthur Supervised Learning  is classified into 1.Classification 2. Regression\n",
    "\n",
    "So one of the Supervised learning Classifier is Logistic Regression. The name itself is showing Regression but it is actually a classification algorithm.\n",
    "\n",
    "Any Algorithm contains 2 types of variable 1.Dependent Varible 2.Independent Variable.\n",
    "\n",
    "Logistic Regression is used to prevent categorical dependent variable using independent variables by using Logistic Function. So output of Logistic Regression must be categorical value(0 | 1 | YES | NO). It uses S-curve by which we can classify the samples.\n",
    "\n",
    "Logistic function equation is Probability(1/(1+e-(W(^(T) * X)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is also a Supervised Learning algorithm. It deals with both classification and Regression Problems.\n",
    "\n",
    "Decision Tree is used to prevent categorical and numeric dependent variable using independent variables by constructing Decision Tree and follows Greedy Manner. To construct Decision Tree we need to calculate Information Gain or Gini Index for all the dependent features and represent the highest value feature as root node.\n",
    "\n",
    "So output of Decision tree is \"a decision\" - the predicted value for the input. \n",
    "\n",
    "\n",
    "Gini Index = 1-Σ(p)^2 \n",
    "\n",
    "where p is probability of each individual dependent class variable.\n",
    "\n",
    "GINI(Split) = Σ k/n GINI(i) - to choose the root node\n",
    "\n",
    "where k is the number of records at child(i)\n",
    "      n is the number of records at parent.\n",
    "      \n",
    "\n",
    "Entropy = -Σ(p log p)\n",
    "where p is probability of each individual dependent class variable.\n",
    "\n",
    "Information Gain = Entropy(parent)  - Σ k/n Entropy(i)\n",
    "where k is the number of records at child(i)\n",
    "      n is the number of records at parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemblers is also a Supervised Learning algorithm.\n",
    "\n",
    "Ensemblers means instead of learning one classifier it will learn multiple classifiers to build the model.\n",
    "\n",
    "Ensemblers are of 2 types 1.Independent 2.Sequence\n",
    "\n",
    "Random Forest is one of the Independent Ensemble learning algorithm. \n",
    "\n",
    "Random Forest will divide the entire original Dataset into mutiple subsets based on random with replacement technique.So each dataset may contains duplicates also. \n",
    "\n",
    "After divide the data,basically unlike of Decision Tree it follows Non-Greedy Approach means Instead of taking highest value from all features,\n",
    "Random Forest randomly taken the features and find the Information Gain or Gini Index values of randomly taken features and pick the highest value feature as root node and do same for child nodes as well.\n",
    "So will get the better accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
